#!/usr/bin/env python3
"""
ğŸ”„ Workflow Manager (Sin PyTorch)
Gestiona el flujo de trabajo entre mÃ¡quina local y GPU
"""

import os
import sys
import json
import shutil
from pathlib import Path
from datetime import datetime

class NoTorchWorkflow:
    """Gestor de workflow sin PyTorch."""
    
    def __init__(self, base_dir="."):
        self.base_dir = Path(base_dir)
        self.datasets_dir = self.base_dir / "datasets"
        self.models_dir = self.base_dir / "models"
        self.batches_dir = self.base_dir / "batches"
        self.results_dir = self.base_dir / "results"
        
        # Crear directorios necesarios
        for dir_path in [self.batches_dir, self.results_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def list_available_models(self):
        """Lista modelos disponibles."""
        print("ğŸ” Buscando modelos disponibles...")
        
        model_files = []
        for ext in ["*.pt", "*.pth", "*.onnx"]:
            model_files.extend(list(self.models_dir.glob(f"**/{ext}")))
            
        if not model_files:
            print("âŒ No se encontraron modelos")
            print(f"ğŸ’¡ Busca en: {self.models_dir}")
            return []
            
        print(f"âœ… Encontrados {len(model_files)} modelos:")
        for i, model in enumerate(model_files, 1):
            size_mb = model.stat().st_size / (1024*1024)
            print(f"   {i}. {model.name} ({size_mb:.1f} MB)")
            print(f"      ğŸ“ {model.parent}")
            
        return model_files
    
    def list_available_datasets(self):
        """Lista datasets disponibles."""
        print("ğŸ“Š Buscando datasets disponibles...")
        
        datasets = []
        for item in self.datasets_dir.iterdir():
            if item.is_dir():
                data_yaml = item / "data.yaml"
                if data_yaml.exists():
                    datasets.append(item)
                    
        if not datasets:
            print("âŒ No se encontraron datasets")
            print(f"ğŸ’¡ Busca en: {self.datasets_dir}")
            return []
            
        print(f"âœ… Encontrados {len(datasets)} datasets:")
        for i, dataset in enumerate(datasets, 1):
            print(f"   {i}. {dataset.name}")
            
            # Leer info del data.yaml
            try:
                import yaml
                with open(dataset / "data.yaml", 'r') as f:
                    data = yaml.safe_load(f)
                print(f"      ğŸ“‹ Clases: {data.get('nc', 'N/A')}")
                
                # Contar imÃ¡genes
                for split in ['train', 'val', 'test']:
                    split_dir = dataset / split / "images"
                    if split_dir.exists():
                        count = len(list(split_dir.glob("*.jpg")) + list(split_dir.glob("*.png")))
                        print(f"      ğŸ“¸ {split}: {count} imÃ¡genes")
                        
            except Exception as e:
                print(f"      âš ï¸ Error leyendo metadata: {e}")
                
        return datasets
    
    def create_test_batch(self, model_name, dataset_name, max_images=10, splits=["val"]):
        """Crea un lote de prueba."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        batch_id = f"{model_name}_{dataset_name}_{timestamp}"
        batch_dir = self.batches_dir / batch_id
        batch_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“¦ Creando lote: {batch_id}")
        
        dataset_path = self.datasets_dir / dataset_name
        if not dataset_path.exists():
            print(f"âŒ Dataset no encontrado: {dataset_path}")
            return None
            
        batch_info = {
            'batch_id': batch_id,
            'model_name': model_name,
            'dataset_name': dataset_name,
            'created_at': timestamp,
            'max_images': max_images,
            'splits': splits,
            'total_images': 0,
            'files': []
        }
        
        total_copied = 0
        
        for split in splits:
            split_dir = dataset_path / split / "images"
            if not split_dir.exists():
                print(f"âš ï¸ Split no encontrado: {split}")
                continue
                
            # Crear directorio para este split
            batch_split_dir = batch_dir / split
            batch_split_dir.mkdir(exist_ok=True)
            
            # Buscar imÃ¡genes
            image_files = list(split_dir.glob("*.jpg")) + list(split_dir.glob("*.png"))
            image_files = image_files[:max_images]
            
            print(f"ğŸ“¸ Copiando {len(image_files)} imÃ¡genes de {split}...")
            
            for i, img_file in enumerate(image_files):
                dest_file = batch_split_dir / f"{split}_{i+1:03d}_{img_file.name}"
                shutil.copy2(img_file, dest_file)
                batch_info['files'].append(str(dest_file.relative_to(batch_dir)))
                total_copied += 1
        
        batch_info['total_images'] = total_copied
        
        # Copiar data.yaml
        data_yaml = dataset_path / "data.yaml"
        if data_yaml.exists():
            shutil.copy2(data_yaml, batch_dir / "data.yaml")
            
        # Guardar informaciÃ³n del lote
        with open(batch_dir / "batch_info.json", 'w') as f:
            json.dump(batch_info, f, indent=2)
            
        # Crear README con instrucciones
        readme_content = f"""# Lote de Prueba: {batch_id}

## ğŸ“‹ InformaciÃ³n
- **Modelo**: {model_name}
- **Dataset**: {dataset_name}
- **Creado**: {timestamp}
- **Total imÃ¡genes**: {total_copied}

## ğŸš€ Instrucciones para GPU

1. **Transferir este directorio** a la mÃ¡quina con GPU
2. **Instalar dependencias** (si no estÃ¡n):
   ```bash
   pip install ultralytics opencv-python
   ```
3. **Ejecutar inferencia**:
   ```bash
   python gpu_inference.py path/to/model.pt {batch_id} output_results/
   ```
4. **Transferir resultados** de vuelta a la mÃ¡quina local

## ğŸ“ Estructura
```
{batch_id}/
â”œâ”€â”€ batch_info.json    # InformaciÃ³n del lote
â”œâ”€â”€ data.yaml         # ConfiguraciÃ³n del dataset
â”œâ”€â”€ README.md         # Este archivo
â””â”€â”€ val/              # ImÃ¡genes de validaciÃ³n
    â”œâ”€â”€ val_001_*.jpg
    â”œâ”€â”€ val_002_*.jpg
    â””â”€â”€ ...
```

## ğŸ”„ Procesamiento Local
Una vez que tengas los resultados:
```bash
python model_tools_no_torch.py --action process --results path/to/results/
```
"""
        
        with open(batch_dir / "README.md", 'w') as f:
            f.write(readme_content)
            
        print(f"âœ… Lote creado: {batch_dir}")
        print(f"ğŸ“‹ Total imÃ¡genes: {total_copied}")
        print(f"ğŸ“ Para transferir: {batch_dir}")
        
        return batch_dir
    
    def list_batches(self):
        """Lista lotes creados."""
        print("ğŸ“¦ Lotes disponibles:")
        
        batches = list(self.batches_dir.glob("*/batch_info.json"))
        
        if not batches:
            print("âŒ No se encontraron lotes")
            return []
            
        batch_info_list = []
        for i, batch_file in enumerate(batches, 1):
            try:
                with open(batch_file, 'r') as f:
                    info = json.load(f)
                    
                batch_info_list.append(info)
                print(f"   {i}. {info['batch_id']}")
                print(f"      ğŸ“‹ Modelo: {info['model_name']}")
                print(f"      ğŸ“Š Dataset: {info['dataset_name']}")
                print(f"      ğŸ“¸ ImÃ¡genes: {info['total_images']}")
                print(f"      ğŸ•’ Creado: {info['created_at']}")
                
            except Exception as e:
                print(f"   âŒ Error leyendo {batch_file}: {e}")
                
        return batch_info_list
    
    def process_results(self, results_dir):
        """Procesa resultados de GPU."""
        results_dir = Path(results_dir)
        
        if not results_dir.exists():
            print(f"âŒ Directorio de resultados no encontrado: {results_dir}")
            return
            
        print(f"ğŸ“Š Procesando resultados en: {results_dir}")
        
        # Buscar archivos de resultados
        result_files = list(results_dir.glob("results*.json"))
        image_files = list(results_dir.glob("predicted_*.jpg")) + list(results_dir.glob("predicted_*.png"))
        
        print(f"ğŸ“„ Archivos JSON: {len(result_files)}")
        print(f"ğŸ–¼ï¸ ImÃ¡genes predichas: {len(image_files)}")
        
        if not result_files:
            print("âŒ No se encontraron archivos de resultados JSON")
            return
            
        # Procesar cada archivo de resultados
        all_results = []
        for result_file in result_files:
            try:
                with open(result_file, 'r') as f:
                    data = json.load(f)
                    all_results.append(data)
                    print(f"âœ… Procesado: {result_file.name}")
            except Exception as e:
                print(f"âŒ Error al leer {result_file.name}: {e}")
        
        # Generar resumen
        self.generate_summary_report(all_results, results_dir)
        
        return all_results
    
    def generate_summary_report(self, results, output_dir):
        """Genera reporte resumen."""
        print(f"\nğŸ“Š GENERANDO REPORTE RESUMEN...")
        
        total_images = 0
        total_detections = 0
        class_counts = {}
        confidences = []
        
        for result_set in results:
            if 'results' in result_set:
                total_images += len(result_set['results'])
                
                for result in result_set['results']:
                    if 'detections' in result:
                        total_detections += len(result['detections'])
                        
                        for detection in result['detections']:
                            class_name = detection.get('class', 'unknown')
                            confidence = detection.get('confidence', 0)
                            
                            if class_name not in class_counts:
                                class_counts[class_name] = 0
                            class_counts[class_name] += 1
                            confidences.append(confidence)
        
        # Crear reporte
        report = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_images': total_images,
                'total_detections': total_detections,
                'avg_detections_per_image': total_detections / max(total_images, 1),
                'class_distribution': class_counts,
                'avg_confidence': sum(confidences) / max(len(confidences), 1) if confidences else 0,
                'confidence_stats': {
                    'min': min(confidences) if confididences else 0,
                    'max': max(confidences) if confidences else 0,
                    'count': len(confidences)
                }
            },
            'raw_results': results
        }
        
        # Guardar reporte
        report_file = Path(output_dir) / "summary_report.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
            
        # Mostrar resumen en consola
        print(f"\nğŸ“Š RESUMEN DE RESULTADOS:")
        print(f"   ğŸ“¸ Total imÃ¡genes: {total_images}")
        print(f"   ğŸ¯ Total detecciones: {total_detections}")
        print(f"   ğŸ“ˆ Promedio por imagen: {total_detections / max(total_images, 1):.2f}")
        print(f"   ğŸ·ï¸ Clases detectadas:")
        for class_name, count in class_counts.items():
            percentage = (count / total_detections * 100) if total_detections > 0 else 0
            print(f"     {class_name}: {count} ({percentage:.1f}%)")
        if confidences:
            print(f"   ğŸ“Š Confianza promedio: {sum(confidences) / len(confidences):.3f}")
            
        print(f"\nğŸ’¾ Reporte guardado: {report_file}")
    
    def list_processed_results(self):
        """Lista resultados procesados disponibles."""
        print("ğŸ” Buscando resultados procesados...")
        
        # Buscar en directorio de resultados
        result_dirs = []
        for item in self.results_dir.iterdir():
            if item.is_dir():
                # Buscar archivos de resumen
                summary_files = list(item.glob("summary_report.json"))
                result_files = list(item.glob("results*.json"))
                
                if summary_files or result_files:
                    result_dirs.append(item)
        
        if not result_dirs:
            print("âŒ No se encontraron resultados procesados")
            print(f"ğŸ’¡ Busca en: {self.results_dir}")
            return []
            
        print(f"âœ… Encontrados {len(result_dirs)} directorios con resultados:")
        for i, result_dir in enumerate(result_dirs, 1):
            print(f"   {i}. {result_dir.name}")
            
            # Mostrar info bÃ¡sica si existe resumen
            summary_file = result_dir / "summary_report.json"
            if summary_file.exists():
                try:
                    with open(summary_file, 'r') as f:
                        summary = json.load(f)
                    stats = summary.get('summary', {})
                    print(f"      ğŸ“¸ ImÃ¡genes: {stats.get('total_images', 'N/A')}")
                    print(f"      ğŸ¯ Detecciones: {stats.get('total_detections', 'N/A')}")
                    print(f"      ğŸ“Š Confianza: {stats.get('avg_confidence', 0):.3f}")
                except:
                    pass
                    
        return result_dirs
    
    def show_detailed_results(self, results_dir):
        """Muestra resultados detallados de un directorio."""
        results_dir = Path(results_dir)
        
        if not results_dir.exists():
            print(f"âŒ Directorio no encontrado: {results_dir}")
            return
            
        print(f"ğŸ“Š RESULTADOS DETALLADOS: {results_dir.name}")
        print("=" * 50)
        
        # Leer resumen si existe
        summary_file = results_dir / "summary_report.json"
        if summary_file.exists():
            try:
                with open(summary_file, 'r') as f:
                    summary = json.load(f)
                
                stats = summary.get('summary', {})
                print(f"ğŸ“Š ESTADÃSTICAS GENERALES:")
                print(f"   ğŸ“¸ Total imÃ¡genes: {stats.get('total_images', 'N/A')}")
                print(f"   ğŸ¯ Total detecciones: {stats.get('total_detections', 'N/A')}")
                print(f"   ğŸ“ˆ Promedio por imagen: {stats.get('avg_detections_per_image', 0):.2f}")
                print(f"   ğŸ“Š Confianza promedio: {stats.get('avg_confidence', 0):.3f}")
                
                conf_stats = stats.get('confidence_stats', {})
                if conf_stats:
                    print(f"   ğŸ“Š Rango confianza: {conf_stats.get('min', 0):.3f} - {conf_stats.get('max', 0):.3f}")
                
                # DistribuciÃ³n de clases
                class_dist = stats.get('class_distribution', {})
                if class_dist:
                    print(f"\nğŸ·ï¸ DISTRIBUCIÃ“N DE CLASES:")
                    total_detections = stats.get('total_detections', 0)
                    for class_name, count in sorted(class_dist.items(), key=lambda x: x[1], reverse=True):
                        percentage = (count / total_detections * 100) if total_detections > 0 else 0
                        print(f"   {class_name}: {count} detecciones ({percentage:.1f}%)")
                        
            except Exception as e:
                print(f"âŒ Error leyendo resumen: {e}")
        
        # Listar archivos de imÃ¡genes disponibles
        image_files = list(results_dir.glob("predicted_*.jpg")) + list(results_dir.glob("predicted_*.png"))
        if image_files:
            print(f"\nğŸ–¼ï¸ IMÃGENES PROCESADAS ({len(image_files)}):")
            for i, img_file in enumerate(image_files[:10], 1):  # Mostrar primeras 10
                print(f"   {i}. {img_file.name}")
            if len(image_files) > 10:
                print(f"   ... y {len(image_files) - 10} mÃ¡s")
    
    def show_images_with_detections(self, results_dir):
        """Intenta mostrar imÃ¡genes con detecciones usando herramientas del sistema."""
        results_dir = Path(results_dir)
        
        if not results_dir.exists():
            print(f"âŒ Directorio no encontrado: {results_dir}")
            return
            
        # Buscar imÃ¡genes procesadas
        image_files = list(results_dir.glob("predicted_*.jpg")) + list(results_dir.glob("predicted_*.png"))
        
        if not image_files:
            print(f"âŒ No se encontraron imÃ¡genes procesadas en: {results_dir}")
            return
            
        print(f"ğŸ–¼ï¸ Encontradas {len(image_files)} imÃ¡genes procesadas")
        print("ğŸ” Opciones de visualizaciÃ³n:")
        print("   1. ğŸ“ Abrir carpeta en Finder/Explorer")
        print("   2. ğŸ–¼ï¸ Abrir primera imagen")
        print("   3. ğŸ“‹ Listar todas las imÃ¡genes")
        print("   0. â¬…ï¸ Volver")
        
        choice = input("\nğŸ¯ Selecciona opciÃ³n: ").strip()
        
        if choice == "1":
            # Abrir carpeta
            import subprocess
            try:
                if sys.platform == "darwin":  # macOS
                    subprocess.run(["open", str(results_dir)], check=True)
                elif sys.platform == "win32":  # Windows
                    subprocess.run(["explorer", str(results_dir)], check=True)
                else:  # Linux
                    subprocess.run(["xdg-open", str(results_dir)], check=True)
                print(f"âœ… Carpeta abierta: {results_dir}")
            except Exception as e:
                print(f"âŒ Error abriendo carpeta: {e}")
                
        elif choice == "2":
            # Abrir primera imagen
            import subprocess
            try:
                first_image = image_files[0]
                if sys.platform == "darwin":  # macOS
                    subprocess.run(["open", str(first_image)], check=True)
                elif sys.platform == "win32":  # Windows
                    subprocess.run(["start", str(first_image)], shell=True, check=True)
                else:  # Linux
                    subprocess.run(["xdg-open", str(first_image)], check=True)
                print(f"âœ… Imagen abierta: {first_image.name}")
            except Exception as e:
                print(f"âŒ Error abriendo imagen: {e}")
                
        elif choice == "3":
            # Listar todas las imÃ¡genes
            print(f"\nğŸ“‹ TODAS LAS IMÃGENES PROCESADAS:")
            for i, img_file in enumerate(image_files, 1):
                size_kb = img_file.stat().st_size / 1024
                print(f"   {i:2d}. {img_file.name} ({size_kb:.1f} KB)")
    
    def generate_statistics_report(self, results_dir):
        """Genera estadÃ­sticas avanzadas de los resultados."""
        results_dir = Path(results_dir)
        
        # Leer resumen existente
        summary_file = results_dir / "summary_report.json"
        if not summary_file.exists():
            print(f"âŒ No se encontrÃ³ resumen en: {results_dir}")
            print("ğŸ’¡ Ejecuta primero 'Procesar resultados de GPU'")
            return
            
        try:
            with open(summary_file, 'r') as f:
                summary = json.load(f)
        except Exception as e:
            print(f"âŒ Error leyendo resumen: {e}")
            return
            
        stats = summary.get('summary', {})
        raw_results = summary.get('raw_results', [])
        
        print(f"ğŸ“ˆ ESTADÃSTICAS AVANZADAS: {results_dir.name}")
        print("=" * 60)
        
        # EstadÃ­sticas bÃ¡sicas
        total_images = stats.get('total_images', 0)
        total_detections = stats.get('total_detections', 0)
        
        print(f"ğŸ“Š RESUMEN GENERAL:")
        print(f"   ğŸ“¸ Total imÃ¡genes procesadas: {total_images}")
        print(f"   ğŸ¯ Total detecciones: {total_detections}")
        print(f"   ğŸ“ˆ Detecciones por imagen: {total_detections / max(total_images, 1):.2f}")
        
        # AnÃ¡lisis de confianza
        conf_stats = stats.get('confidence_stats', {})
        if conf_stats:
            print(f"\nğŸ“Š ANÃLISIS DE CONFIANZA:")
            print(f"   ğŸ¯ Promedio: {stats.get('avg_confidence', 0):.3f}")
            print(f"   ğŸ“Š MÃ­nima: {conf_stats.get('min', 0):.3f}")
            print(f"   ğŸ“Š MÃ¡xima: {conf_stats.get('max', 0):.3f}")
            print(f"   ğŸ“Š Total mediciones: {conf_stats.get('count', 0)}")
        
        # DistribuciÃ³n de clases
        class_dist = stats.get('class_distribution', {})
        if class_dist:
            print(f"\nğŸ·ï¸ DISTRIBUCIÃ“N DETALLADA DE CLASES:")
            sorted_classes = sorted(class_dist.items(), key=lambda x: x[1], reverse=True)
            
            for class_name, count in sorted_classes:
                percentage = (count / total_detections * 100) if total_detections > 0 else 0
                bar_length = int(percentage / 5)  # Barra visual
                bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
                print(f"   {class_name:12s}: {count:3d} [{bar}] {percentage:5.1f}%")
        
        # AnÃ¡lisis por imagen (si hay datos detallados)
        if raw_results:
            detections_per_image = []
            for result_set in raw_results:
                if 'results' in result_set:
                    for result in result_set['results']:
                        det_count = len(result.get('detections', []))
                        detections_per_image.append(det_count)
            
            if detections_per_image:
                print(f"\nğŸ“ˆ ANÃLISIS POR IMAGEN:")
                print(f"   ğŸ“Š MÃ­nimo detecciones: {min(detections_per_image)}")
                print(f"   ğŸ“Š MÃ¡ximo detecciones: {max(detections_per_image)}")
                print(f"   ğŸ“Š Promedio: {sum(detections_per_image) / len(detections_per_image):.2f}")
                
                # Histograma simple
                print(f"\nğŸ“Š DISTRIBUCIÃ“N DE DETECCIONES:")
                max_det = max(detections_per_image) if detections_per_image else 0
                for i in range(max_det + 1):
                    count = detections_per_image.count(i)
                    if count > 0:
                        bar = "â–ˆ" * (count * 20 // len(detections_per_image))
                        print(f"   {i:2d} det: {count:2d} imgs {bar}")
        
        print(f"\nğŸ’¾ Datos completos en: {summary_file}")

def main():
    workflow = NoTorchWorkflow()
    
    print("ğŸ”„ WORKFLOW MANAGER (Sin PyTorch)")
    print("=" * 50)
    
    while True:
        print("\nğŸ›ï¸ OPCIONES:")
        print("1. ğŸ“‹ Listar modelos disponibles")
        print("2. ğŸ“Š Listar datasets disponibles") 
        print("3. ğŸ“¦ Crear lote de prueba")
        print("4. ğŸ“¦ Listar lotes creados")
        print("5. ğŸ“Š Procesar resultados de GPU")
        print("6. ğŸ” Ver resultados procesados")
        print("7. ğŸ–¼ï¸ Visualizar imÃ¡genes con detecciones")
        print("8. ğŸ“ˆ EstadÃ­sticas detalladas")
        print("0. ğŸšª Salir")
        
        try:
            choice = input("\nğŸ¯ Selecciona una opciÃ³n: ").strip()
            
            if choice == "0":
                print("ğŸ‘‹ Â¡Hasta luego!")
                break
                
            elif choice == "1":
                workflow.list_available_models()
                
            elif choice == "2":
                workflow.list_available_datasets()
                
            elif choice == "3":
                # Crear lote interactivo
                models = workflow.list_available_models()
                if not models:
                    continue
                    
                try:
                    model_idx = int(input("Selecciona modelo (nÃºmero): ")) - 1
                    model_name = models[model_idx].stem
                except (ValueError, IndexError):
                    print("âŒ SelecciÃ³n invÃ¡lida")
                    continue
                
                datasets = workflow.list_available_datasets()
                if not datasets:
                    continue
                    
                try:
                    dataset_idx = int(input("Selecciona dataset (nÃºmero): ")) - 1
                    dataset_name = datasets[dataset_idx].name
                except (ValueError, IndexError):
                    print("âŒ SelecciÃ³n invÃ¡lida")
                    continue
                
                max_images = input("MÃ¡ximo de imÃ¡genes por split (10): ").strip()
                max_images = int(max_images) if max_images else 10
                
                workflow.create_test_batch(model_name, dataset_name, max_images)
                
            elif choice == "4":
                workflow.list_batches()
                
            elif choice == "5":
                results_dir = input("Directorio con resultados de GPU: ").strip()
                if results_dir:
                    workflow.process_results(results_dir)
                else:
                    print("âŒ Directorio requerido")
                    
            elif choice == "6":
                # Ver resultados procesados
                result_dirs = workflow.list_processed_results()
                if result_dirs:
                    try:
                        selection = input("\nğŸ¯ Selecciona resultado (nÃºmero o nombre): ").strip()
                        if selection.isdigit():
                            idx = int(selection) - 1
                            if 0 <= idx < len(result_dirs):
                                workflow.show_detailed_results(result_dirs[idx])
                            else:
                                print("âŒ NÃºmero invÃ¡lido")
                        else:
                            # Buscar por nombre
                            found = False
                            for result_dir in result_dirs:
                                if selection.lower() in result_dir.name.lower():
                                    workflow.show_detailed_results(result_dir)
                                    found = True
                                    break
                            if not found:
                                print("âŒ Resultado no encontrado")
                    except ValueError:
                        print("âŒ Entrada invÃ¡lida")
                        
            elif choice == "7":
                # Visualizar imÃ¡genes
                result_dirs = workflow.list_processed_results()
                if result_dirs:
                    try:
                        selection = input("\nğŸ¯ Selecciona resultado para ver imÃ¡genes (nÃºmero): ").strip()
                        if selection.isdigit():
                            idx = int(selection) - 1
                            if 0 <= idx < len(result_dirs):
                                workflow.show_images_with_detections(result_dirs[idx])
                            else:
                                print("âŒ NÃºmero invÃ¡lido")
                        else:
                            print("âŒ Ingresa un nÃºmero")
                    except ValueError:
                        print("âŒ Entrada invÃ¡lida")
                        
            elif choice == "8":
                # EstadÃ­sticas detalladas
                result_dirs = workflow.list_processed_results()
                if result_dirs:
                    try:
                        selection = input("\nğŸ¯ Selecciona resultado para estadÃ­sticas (nÃºmero): ").strip()
                        if selection.isdigit():
                            idx = int(selection) - 1
                            if 0 <= idx < len(result_dirs):
                                workflow.generate_statistics_report(result_dirs[idx])
                            else:
                                print("âŒ NÃºmero invÃ¡lido")
                        else:
                            print("âŒ Ingresa un nÃºmero")
                    except ValueError:
                        print("âŒ Entrada invÃ¡lida")
                
            else:
                print("âŒ OpciÃ³n no vÃ¡lida")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Â¡Hasta luego!")
            break
        except Exception as e:
            print(f"âŒ Error: {e}")

if __name__ == "__main__":
    main()
