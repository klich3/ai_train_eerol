# ğŸ¦· GUÃA DE USO DEL WORKFLOW MANAGER

## ğŸ“‹ DescripciÃ³n General
El `DataWorkflowManager.py` implementa una estrategia completa para unificar, balancear y preparar datasets dentales para entrenamiento de modelos de IA.

## ğŸ¯ Objetivos del Workflow
- **UnificaciÃ³n**: Convierte todos los datasets a formatos estÃ¡ndar
- **Balanceo**: Identifica y corrige desbalances en las clases
- **OptimizaciÃ³n**: Maximiza el rendimiento mediante fusiÃ³n inteligente
- **EstandarizaciÃ³n**: Normaliza resoluciones y anotaciones

## ğŸ”„ Fases del Workflow

### 1. ğŸ§± UnificaciÃ³n y Preprocesamiento
```
âœ… DetecciÃ³n â†’ YOLO format (.txt + data.yaml)
âœ… SegmentaciÃ³n â†’ COCO format (.json)  
âœ… ClasificaciÃ³n â†’ Estructura de carpetas
âœ… NormalizaciÃ³n de resoluciones (640x640, 1024x1024)
âœ… UnificaciÃ³n de nombres de clases inconsistentes
```

### 2. ğŸ“Š AnÃ¡lisis EstadÃ­stico de Clases
```
ğŸ” Cuenta muestras por clase
âš–ï¸ Identifica desbalances crÃ­ticos
ğŸ“ˆ Calcula factores de augmentaciÃ³n necesarios
ğŸ¯ Propone estrategias de mejora
```

### 3. ğŸ”„ FusiÃ³n de Datasets Similares
```
ğŸ”— Agrupa datasets compatibles:
   â€¢ dental_detection_panoramic
   â€¢ dental_detection_periapical  
   â€¢ dental_segmentation_coco
   â€¢ dental_classification

ğŸ’¡ Genera data.yaml unificado
ğŸ·ï¸ Mapea clases a identificadores Ãºnicos
```

### 4. ğŸ§ª DivisiÃ³n Train/Val/Test
```
ğŸ“Š Split estratificado: 70/20/10
ğŸ‘¥ Evita mezclar datos del mismo paciente
ğŸ² Semilla aleatoria reproducible
âœ… ValidaciÃ³n de distribuciÃ³n balanceada
```

### 5. âš™ï¸ Recomendaciones de Entrenamiento
```
ğŸ¤– Arquitecturas recomendadas por tamaÃ±o:
   â€¢ <5K imÃ¡genes: YOLOv8n, Mask R-CNN ResNet50
   â€¢ <20K imÃ¡genes: YOLOv8s, Mask R-CNN ResNet101  
   â€¢ >20K imÃ¡genes: YOLOv8m/l, ensemble models

âš¡ ConfiguraciÃ³n optimizada:
   â€¢ Learning rates adaptativos
   â€¢ Batch sizes segÃºn hardware
   â€¢ Epochs basados en convergencia esperada
```

## ğŸ·ï¸ Clases Unificadas Soportadas

```yaml
caries: [caries, Caries, CARIES, cavity, decay, Q1_Caries, Q2_Caries, Q3_Caries, Q4_Caries]
tooth: [tooth, teeth, Tooth, TOOTH, diente, molar, premolar, canine, incisor]
filling: [filling, Filling, Fillings, FILLING, restoration, RESTORATION]
crown: [crown, Crown, CROWN, CROWN AND BRIDGE]
implant: [implant, Implant, IMPLANT]
root_canal: [Root Canal Treatment, ROOT CANAL TREATED TOOTH, root canal]
bone_loss: [Bone Loss, BONE LOSS, VERTICAL BONE LOSS]
impacted: [impacted, Impacted, IMPACTED TOOTH, Q1_Impacted, Q2_Impacted, Q3_Impacted, Q4_Impacted]
periapical_lesion: [Periapical lesion, Q1_Periapical_Lesion, Q2_Periapical_Lesion, Q3_Periapical_Lesion, Q4_Periapical_Lesion]
maxillary_sinus: [maxillary sinus, MAXILLARY SINUS, MAXILLARY  SINUS]
mandible: [Mandible, mandible, RAMUS OF MANDIBLE, INFERIOR BORDER OF MANDIBLE]
maxilla: [Maxilla, maxilla]
```

## ğŸš€ Ejemplos de Uso

### Ejecutar Workflow Completo
```bash
cd /Volumes/3TB/Ai/XRAY
python DataWorkflowManager.py
# Seleccionar opciÃ³n 6: "Ejecutar workflow completo"
```

### Crear Dataset YOLO Unificado
```python
from DataWorkflowManager import DentalDataWorkflowManager

manager = DentalDataWorkflowManager(
    base_path="/Volumes/3TB/Ai/XRAY/_dataSets",
    output_path="/Volumes/3TB/Ai/XRAY/processed_datasets"
)

# Datasets a fusionar
datasets_to_merge = [
    "dental_diseases_yolo",
    "Dental Diseases", 
    "dental_datasetv6",
    "Dental 3"
]

# Crear dataset unificado
unified_path = manager.create_unified_yolo_dataset(
    data=manager.load_analysis_data(),
    datasets_to_merge=datasets_to_merge,
    output_name="unified_dental_panoramic_detection"
)
```

### Analizar Balance de Clases
```python
manager = DentalDataWorkflowManager(base_path)
data = manager.load_analysis_data()
class_dist, total_samples = manager.analyze_class_distribution(data)
imbalanced = manager.identify_imbalanced_classes(total_samples)
```

## ğŸ“Š Archivos de Salida

### Estructura de Dataset Unificado
```
unified_dental_detection/
â”œâ”€â”€ data.yaml              # ConfiguraciÃ³n YOLO
â”œâ”€â”€ classes.txt            # Lista de clases
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/            # ImÃ¡genes de entrenamiento
â”‚   â””â”€â”€ labels/            # Anotaciones YOLO (.txt)
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ images/            # ImÃ¡genes de validaciÃ³n  
â”‚   â””â”€â”€ labels/            # Anotaciones YOLO (.txt)
â””â”€â”€ test/
    â”œâ”€â”€ images/            # ImÃ¡genes de prueba
    â””â”€â”€ labels/            # Anotaciones YOLO (.txt)
```

### Archivos de AnÃ¡lisis
```
processed_datasets/
â”œâ”€â”€ workflow_config.json   # ConfiguraciÃ³n completa
â”œâ”€â”€ workflow_analysis.png  # VisualizaciÃ³n del anÃ¡lisis
â”œâ”€â”€ class_distribution.json # DistribuciÃ³n detallada
â””â”€â”€ training_recommendations.json # Recomendaciones
```

## ğŸ¯ Estrategias de AugmentaciÃ³n

### Para Clases Muy Desbalanceadas (< 30% del promedio)
```yaml
techniques: [rotation, brightness, contrast, noise, flip_horizontal]
factor: 3-4x
priority: high
```

### Para Clases Moderadamente Desbalanceadas (30-70% del promedio)  
```yaml
techniques: [rotation, brightness]
factor: 2x
priority: medium
```

## ğŸ¤– Recomendaciones de Entrenamiento

### Dataset PequeÃ±o (< 5,000 imÃ¡genes)
```yaml
architecture: YOLOv8n
epochs: 100
batch_size: 16
learning_rate: 0.01
augmentation: heavy
strategy: transfer_learning
```

### Dataset Mediano (5,000 - 20,000 imÃ¡genes)
```yaml
architecture: YOLOv8s
epochs: 150  
batch_size: 32
learning_rate: 0.01
augmentation: medium
strategy: fine_tuning
```

### Dataset Grande (> 20,000 imÃ¡genes)
```yaml
architecture: YOLOv8m
epochs: 200
batch_size: 32-64
learning_rate: 0.005
augmentation: light
strategy: from_scratch + ensemble
```

## ğŸ’» Requisitos de Hardware

### ConfiguraciÃ³n MÃ­nima
- GPU: RTX 3060 (8GB VRAM)
- RAM: 16GB
- Storage: 100GB SSD
- Tiempo estimado: 4-12 horas

### ConfiguraciÃ³n Recomendada  
- GPU: RTX 4090 (24GB VRAM)
- RAM: 32GB+
- Storage: 500GB+ NVMe SSD
- Tiempo estimado: 2-7 dÃ­as

## ğŸ”§ PersonalizaciÃ³n

### Modificar Ratios de DivisiÃ³n
```python
manager.workflow_config['train_ratio'] = 0.8
manager.workflow_config['val_ratio'] = 0.15  
manager.workflow_config['test_ratio'] = 0.05
```

### AÃ±adir Nuevas Clases Unificadas
```python
manager.unified_classes['nueva_clase'] = ['variante1', 'variante2', 'VARIANTE3']
```

### Cambiar Resoluciones EstÃ¡ndar
```python
manager.standard_resolutions['yolo'] = (512, 512)
manager.standard_resolutions['coco'] = (800, 800)
```

## âš ï¸ Consideraciones Importantes

1. **Backup**: Siempre haz backup de datasets originales antes de procesarlos
2. **Memoria**: Datasets grandes requieren RAM suficiente para procesamiento
3. **ValidaciÃ³n**: Revisa manualmente muestras del dataset unificado
4. **Consistencia**: Verifica que las anotaciones se conserven correctamente
5. **Derechos**: Respeta licencias y tÃ©rminos de uso de datasets pÃºblicos

## ğŸ†˜ SoluciÃ³n de Problemas

### Error: "No se encontrÃ³ dental_dataset_analysis.json"
```bash
# Ejecutar primero el anÃ¡lisis de datasets
python script.py
```

### Error de memoria durante procesamiento
```python
# Procesar en lotes mÃ¡s pequeÃ±os
manager.workflow_config['batch_processing'] = True
manager.workflow_config['batch_size'] = 1000
```

### Clases no reconocidas
```python
# AÃ±adir mapeo manual
manager.unified_classes['clase_personalizada'] = ['nombre_original']
```
