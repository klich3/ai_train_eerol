"""
ü¶∑ Structure Generator
Generador de estructura de directorios y documentaci√≥n para dental-ai
"""

import yaml
from pathlib import Path
from datetime import datetime


class StructureGenerator:
    """Generador de estructura de directorios y documentaci√≥n."""
    
    def __init__(self, output_path: Path):
        self.output_path = output_path
        
        # Configuraci√≥n de la estructura dental-ai
        self.dental_ai_structure = {
            'datasets': {
                'detection_combined': 'YOLO format fusionados',
                'segmentation_coco': 'COCO format unificado', 
                'segmentation_bitmap': 'M√°scaras para U-Net',
                'classification': 'Clasificaci√≥n por carpetas'
            },
            'models': {
                'yolo_detect': 'Modelos YOLO detecci√≥n',
                'yolo_segment': 'Modelos YOLO segmentaci√≥n',
                'unet_teeth': 'Modelos U-Net dientes',
                'cnn_classifier': 'Clasificadores CNN'
            },
            'training': {
                'scripts': 'Scripts de entrenamiento',
                'configs': 'Configuraciones de entrenamiento',
                'logs': 'Logs de entrenamiento'
            },
            'api': {
                'main.py': 'API principal',
                'models': 'Modelos para la API',
                'utils': 'Utilidades'
            },
            'docs': 'Documentaci√≥n'
        }
    
    def create_dental_ai_structure(self):
        """üèóÔ∏è Crea la estructura completa de dental-ai si no existe."""
        print("\nüèóÔ∏è INICIALIZANDO ESTRUCTURA DENTAL-AI...")
        
        structure_created = []
        
        # Crear directorios principales
        for main_dir, content in self.dental_ai_structure.items():
            main_path = self.output_path / main_dir
            main_path.mkdir(parents=True, exist_ok=True)
            structure_created.append(str(main_path))
            
            if isinstance(content, dict):
                for sub_dir, description in content.items():
                    sub_path = main_path / sub_dir
                    sub_path.mkdir(parents=True, exist_ok=True)
                    structure_created.append(str(sub_path))
                    
                    # Crear archivo README para cada subdirectorio
                    readme_path = sub_path / 'README.md'
                    if not readme_path.exists():
                        with open(readme_path, 'w', encoding='utf-8') as f:
                            f.write(f"# {sub_dir.replace('_', ' ').title()}\n\n")
                            f.write(f"{description}\n\n")
                            f.write(f"Creado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            elif main_dir == 'training':
                # Crear subdirectorios espec√≠ficos de training
                for sub_dir in ['scripts', 'configs', 'logs']:
                    sub_path = main_path / sub_dir
                    sub_path.mkdir(parents=True, exist_ok=True)
                    structure_created.append(str(sub_path))
        
        # Crear archivos principales
        self.create_main_documentation()
        self.create_requirements_file()
        self.create_main_config()
        
        print(f"‚úÖ Estructura dental-ai creada con {len(structure_created)} directorios")
        return structure_created
    
    def create_main_documentation(self):
        """Crea documentaci√≥n principal del proyecto dental-ai."""
        readme_path = self.output_path / 'README.md'
        
        readme_content = f"""# ü¶∑ Dental AI - Sistema de An√°lisis Dental con IA

Proyecto completo para an√°lisis dental usando deep learning, generado autom√°ticamente por DataWorkflowManager.

## üìÅ Estructura del Proyecto

```
dental-ai/
‚îú‚îÄ‚îÄ datasets/           # Datasets procesados y listos para entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ detection_combined/     # Datasets YOLO fusionados para detecci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ segmentation_coco/      # Datasets COCO para segmentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ segmentation_bitmap/    # M√°scaras para U-Net
‚îÇ   ‚îî‚îÄ‚îÄ classification/         # Datasets para clasificaci√≥n
‚îú‚îÄ‚îÄ models/             # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ yolo_detect/           # Modelos YOLO para detecci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ yolo_segment/          # Modelos YOLO para segmentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ unet_teeth/            # Modelos U-Net para dientes
‚îÇ   ‚îî‚îÄ‚îÄ cnn_classifier/        # Clasificadores CNN
‚îú‚îÄ‚îÄ training/           # Scripts y configuraciones de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ scripts/               # Scripts de entrenamiento automatizados
‚îÇ   ‚îú‚îÄ‚îÄ configs/               # Configuraciones espec√≠ficas
‚îÇ   ‚îî‚îÄ‚îÄ logs/                  # Logs de entrenamiento
‚îú‚îÄ‚îÄ api/                # API REST para inferencia
‚îú‚îÄ‚îÄ docs/               # Documentaci√≥n adicional
‚îî‚îÄ‚îÄ README.md          # Este archivo
```

## üöÄ Inicio R√°pido

### 1. Instalaci√≥n de Dependencias
```bash
pip install -r requirements.txt
```

### 2. Entrenamiento de Modelos
```bash
cd training/scripts
bash train_[nombre_dataset].sh
```

### 3. Uso de la API
```bash
cd api
python main.py
```

## üìä Datasets Disponibles

Los datasets est√°n organizados por tipo de tarea:

- **Detecci√≥n**: Datasets YOLO para detectar estructuras dentales
- **Segmentaci√≥n**: Datasets COCO y m√°scaras bitmap para segmentaci√≥n precisa
- **Clasificaci√≥n**: Datasets organizados por carpetas para clasificaci√≥n de patolog√≠as

## üîß Configuraci√≥n

Todos los par√°metros de entrenamiento est√°n en `training/configs/`.

## üìù Logs y Monitoreo

Los logs de entrenamiento se guardan en `training/logs/` con timestamps.

## üõ°Ô∏è Protecci√≥n de Datos

Este proyecto utiliza un sistema de seguridad que:
- ‚úÖ NUNCA modifica los datos originales
- ‚úÖ Crea copias de solo lectura
- ‚úÖ Verifica la integridad de los archivos copiados
- ‚úÖ Mantiene logs completos de todas las operaciones

## üìà Desarrollo

Generado autom√°ticamente el {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} por DataWorkflowManager.

Para regenerar o actualizar datasets, utiliza el DataWorkflowManager en el directorio padre.
"""
        
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
    
    def create_requirements_file(self):
        """Crea archivo de requirements para el proyecto dental-ai."""
        req_path = self.output_path / 'requirements.txt'
        
        requirements = [
            "# ü¶∑ Dental AI Requirements",
            "# Core ML",
            "torch>=2.0.0",
            "torchvision>=0.15.0",
            "ultralytics>=8.0.0",
            "detectron2",
            "",
            "# Computer Vision",
            "opencv-python>=4.8.0",
            "Pillow>=9.5.0",
            "albumentations>=1.3.0",
            "",
            "# Data Science",
            "numpy>=1.24.0",
            "pandas>=2.0.0", 
            "matplotlib>=3.7.0",
            "seaborn>=0.12.0",
            "scikit-learn>=1.3.0",
            "",
            "# API",
            "fastapi>=0.100.0",
            "uvicorn[standard]>=0.22.0",
            "pydantic>=2.0.0",
            "",
            "# Utils",
            "tqdm>=4.65.0",
            "pyyaml>=6.0",
            "requests>=2.31.0",
            "",
            "# Development",
            "jupyter>=1.0.0",
            "ipywidgets>=8.0.0"
        ]
        
        with open(req_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(requirements))
    
    def create_main_config(self):
        """Crea configuraci√≥n principal del proyecto."""
        config_path = self.output_path / 'config.yaml'
        
        config = {
            'project': {
                'name': 'dental-ai',
                'version': '1.0.0',
                'created': datetime.now().isoformat(),
                'description': 'Sistema de an√°lisis dental con IA'
            },
            'training': {
                'default_epochs': 100,
                'default_batch_size': 16,
                'default_img_size': 640,
                'patience': 20,
                'save_period': 10
            },
            'paths': {
                'datasets': 'datasets/',
                'models': 'models/',
                'training': 'training/',
                'api': 'api/',
                'logs': 'training/logs/'
            },
            'safety': {
                'preserve_originals': True,
                'verify_copies': True,
                'create_backups': True,
                'read_only_source': True
            }
        }
        
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
