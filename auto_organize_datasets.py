#!/usr/bin/env python3
"""
ü§ñ Auto-Organizador Inteligente de Datasets Dentales
====================================================

Escanea carpetas sueltas en _dataSets, detecta su tipo autom√°ticamente,
convierte al formato est√°ndar y las mueve a la carpeta correspondiente.

Author: Anton Sychev
Created: 2025-07-05
"""

import os
import sys
import json
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import cv2
import numpy as np

# Agregar ruta de m√≥dulos
sys.path.append(str(Path(__file__).parent / "Src"))


class SmartDatasetOrganizer:
    """ü§ñ Organizador inteligente de datasets"""
    
    def __init__(self, base_path: str = "_dataSets", min_images: int = 5):
        self.base_path = Path(base_path)
        self.organized_folders = {"_YOLO", "_COCO", "_UNET", "_pure images and masks", "Archivo", "Dataset"}
        self.supported_image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
        self.min_images = min_images  # M√≠nimo de im√°genes para considerar un dataset v√°lido
        
        # Contadores para estad√≠sticas
        self.stats = {
            'carpetas_analizadas': 0,
            'subcarpetas_encontradas': 0,
            'datasets_detectados': 0,
            'datasets_convertidos': 0,
            'datasets_movidos': 0,
            'datasets_muy_peque√±os': 0,
            'errores': 0
        }
    
    def scan_unorganized_folders(self) -> List[Path]:
        """üîç Escanea recursivamente carpetas que no est√°n organizadas."""
        print("üîç ESCANEANDO CARPETAS NO ORGANIZADAS...")
        
        unorganized = []
        
        if not self.base_path.exists():
            print(f"‚ùå El directorio {self.base_path} no existe")
            return unorganized
        
        def scan_recursive(current_path: Path, depth: int = 0, max_depth: int = 3):
            """Escanea recursivamente hasta una profundidad m√°xima"""
            if depth > max_depth:
                return
                
            for item in current_path.iterdir():
                if (item.is_dir() and 
                    not item.name.startswith('.') and
                    item.name not in self.organized_folders):
                    
                    # Si estamos en el nivel base, evitar carpetas organizadas
                    if depth == 0 and item.name in self.organized_folders:
                        continue
                    
                    # Contar im√°genes en esta carpeta (recursivamente)
                    image_count = self._count_images_recursive(item)
                    
                    if image_count >= self.min_images:
                        unorganized.append(item)
                        print(f"   üìÅ Encontrada: {item.relative_to(self.base_path)} ({image_count} im√°genes)")
                    elif image_count > 0:
                        print(f"   ÔøΩ Muy peque√±a: {item.relative_to(self.base_path)} ({image_count} im√°genes)")
                        self.stats['datasets_muy_peque√±os'] += 1
                    
                    # Continuar escaneando subcarpetas si no tiene suficientes im√°genes
                    if image_count < self.min_images:
                        scan_recursive(item, depth + 1, max_depth)
                    
                    self.stats['subcarpetas_encontradas'] += 1
        
        # Iniciar escaneo recursivo
        scan_recursive(self.base_path)
        
        print(f"üìä Total carpetas v√°lidas: {len(unorganized)}")
        print(f"üìä Carpetas muy peque√±as: {self.stats['datasets_muy_peque√±os']}")
        return unorganized
    
    def _count_images_recursive(self, folder_path: Path) -> int:
        """Cuenta im√°genes recursivamente en una carpeta"""
        count = 0
        try:
            for ext in self.supported_image_extensions:
                count += len(list(folder_path.glob(f"**/*{ext}")))
        except Exception:
            pass
        return count
    
    def detect_dataset_type(self, folder_path: Path) -> Tuple[str, Dict]:
        """üîç Detecta autom√°ticamente el tipo de dataset."""
        print(f"\nüîç Analizando: {folder_path.relative_to(self.base_path)}")
        
        # Obtener archivos de la carpeta recursivamente
        all_files = list(folder_path.rglob("*"))
        image_files = [f for f in all_files if f.suffix.lower() in self.supported_image_extensions]
        txt_files = [f for f in all_files if f.suffix.lower() == '.txt']
        json_files = [f for f in all_files if f.suffix.lower() == '.json']
        xml_files = [f for f in all_files if f.suffix.lower() == '.xml']
        
        info = {
            'total_files': len(all_files),
            'images': len(image_files),
            'txt_files': len(txt_files),
            'json_files': len(json_files),
            'xml_files': len(xml_files),
            'folder_structure': self._analyze_folder_structure(folder_path),
            'size_mb': self._calculate_folder_size(folder_path)
        }
        
        print(f"   üìä Im√°genes: {info['images']}, TXT: {info['txt_files']}, JSON: {info['json_files']}, XML: {info['xml_files']}")
        print(f"   üíæ Tama√±o: {info['size_mb']:.1f} MB")
        
        # Validar que tenga suficientes im√°genes
        if info['images'] < self.min_images:
            print(f"   ‚ö†Ô∏è Muy pocas im√°genes ({info['images']} < {self.min_images})")
            return "TOO_SMALL", info
        
        # 1. DETECTAR YOLO (mayor prioridad si hay archivos .txt)
        if self._is_yolo_format(folder_path, image_files, txt_files):
            return "YOLO", info
        
        # 2. DETECTAR COCO
        if self._is_coco_format(folder_path, image_files, json_files):
            return "COCO", info
        
        # 3. DETECTAR U-NET (m√°scaras)
        if self._is_unet_format(folder_path, image_files):
            return "UNET", info
        
        # 4. DETECTAR PASCAL VOC
        if self._is_pascal_voc_format(folder_path, image_files, xml_files):
            return "PASCAL_VOC", info
        
        # 5. DETECTAR CLASIFICACI√ìN (estructura de carpetas por clase)
        if self._is_classification_format(folder_path, image_files):
            return "CLASSIFICATION", info
        
        # 6. IM√ÅGENES PURAS (sin anotaciones pero con suficientes im√°genes)
        if len(image_files) >= self.min_images:
            return "PURE_IMAGES", info
        
        return "UNKNOWN", info
    
    def _calculate_folder_size(self, folder_path: Path) -> float:
        """Calcula el tama√±o de la carpeta en MB"""
        total_size = 0
        try:
            for file_path in folder_path.rglob("*"):
                if file_path.is_file():
                    total_size += file_path.stat().st_size
        except Exception:
            pass
        return total_size / (1024 * 1024)  # Convert to MB
        
        # 5. DETECTAR PASCAL VOC
        if self._is_pascal_voc_format(folder_path, image_files, xml_files):
            return "PASCAL_VOC", info
        
        # 6. IM√ÅGENES PURAS (sin anotaciones)
        if len(image_files) > 0:
            return "PURE_IMAGES", info
        
        return "UNKNOWN", info
    
    def _is_yolo_format(self, folder_path: Path, image_files: List[Path], txt_files: List[Path]) -> bool:
        """Detecta formato YOLO con validaci√≥n mejorada"""
        if len(image_files) == 0 or len(txt_files) == 0:
            return False
        
        # Verificar que haya correspondencia entre im√°genes y txt files
        image_stems = {img.stem for img in image_files}
        txt_stems = {txt.stem for txt in txt_files}
        
        # Al menos 30% de coincidencias
        matching_ratio = len(image_stems & txt_stems) / len(image_stems)
        if matching_ratio < 0.3:
            return False
        
        # Buscar archivos .txt con coordenadas YOLO v√°lidas
        yolo_annotations = 0
        sample_size = min(10, len(txt_files))
        
        for txt_file in txt_files[:sample_size]:
            try:
                with open(txt_file, 'r') as f:
                    lines = f.readlines()
                    valid_lines = 0
                    for line in lines:
                        parts = line.strip().split()
                        if len(parts) >= 5:  # class x y w h
                            try:
                                # Verificar formato YOLO (valores entre 0 y 1)
                                class_id = int(parts[0])
                                coords = [float(p) for p in parts[1:5]]
                                if (class_id >= 0 and 
                                    all(0 <= c <= 1 for c in coords) and
                                    coords[2] > 0 and coords[3] > 0):  # width y height > 0
                                    valid_lines += 1
                            except ValueError:
                                continue
                    
                    # Si al menos 50% de las l√≠neas son v√°lidas
                    if len(lines) > 0 and valid_lines / len(lines) >= 0.5:
                        yolo_annotations += 1
                        
            except Exception:
                continue
        
        detection_ratio = yolo_annotations / sample_size if sample_size > 0 else 0
        is_yolo = detection_ratio >= 0.4  # 40% de archivos v√°lidos
        
        if is_yolo:
            print(f"   ‚úÖ YOLO detectado: {yolo_annotations}/{sample_size} archivos v√°lidos")
        
        return is_yolo
    
    def _is_coco_format(self, folder_path: Path, image_files: List[Path], json_files: List[Path]) -> bool:
        """Detecta formato COCO con validaci√≥n mejorada"""
        if len(json_files) == 0:
            return False
        
        # Buscar archivos JSON con estructura COCO
        for json_file in json_files:
            try:
                with open(json_file, 'r') as f:
                    data = json.load(f)
                    if (isinstance(data, dict) and 
                        'images' in data and 
                        'annotations' in data and 
                        'categories' in data):
                        
                        # Validar estructura b√°sica
                        images = data.get('images', [])
                        annotations = data.get('annotations', [])
                        categories = data.get('categories', [])
                        
                        if (len(images) > 0 and 
                            len(annotations) > 0 and 
                            len(categories) > 0):
                            print(f"   ‚úÖ COCO detectado: {len(images)} im√°genes, {len(annotations)} anotaciones")
                            return True
            except Exception:
                continue
        
        return False
    
    def _is_unet_format(self, folder_path: Path, image_files: List[Path]) -> bool:
        """Detecta formato U-Net (im√°genes + m√°scaras) con validaci√≥n mejorada"""
        if len(image_files) == 0:
            return False
            
        # Buscar patrones t√≠picos de U-Net
        mask_keywords = {'mask', 'label', 'gt', 'ground_truth', 'seg', 'segmentation', 'annotation'}
        
        # Verificar estructura de carpetas
        subdirs = [d.name.lower() for d in folder_path.rglob("*") if d.is_dir()]
        has_mask_folder = any(keyword in subdir for subdir in subdirs for keyword in mask_keywords)
        
        if has_mask_folder:
            print(f"   ‚úÖ U-Net detectado: carpeta de m√°scaras encontrada")
            return True
        
        # Verificar si hay im√°genes que parecen m√°scaras por nombre
        potential_masks = 0
        sample_size = min(50, len(image_files))
        
        for img_file in image_files[:sample_size]:
            if any(keyword in img_file.name.lower() for keyword in mask_keywords):
                potential_masks += 1
        
        ratio = potential_masks / sample_size if sample_size > 0 else 0
        is_unet = ratio > 0.2  # 20% son m√°scaras
        
        if is_unet:
            print(f"   ‚úÖ U-Net detectado: {potential_masks}/{sample_size} archivos parecen m√°scaras")
        
        return is_unet
    
    def _is_classification_format(self, folder_path: Path, image_files: List[Path]) -> bool:
        """Detecta formato de clasificaci√≥n (carpetas por clase) con validaci√≥n mejorada"""
        if len(image_files) == 0:
            return False
            
        # Verificar estructura: carpetas con nombres de clases
        class_folders = [d for d in folder_path.iterdir() if d.is_dir() and not d.name.startswith('.')]
        
        if len(class_folders) < 2:
            return False
        
        # Verificar que las subcarpetas contengan im√°genes
        images_in_subfolders = 0
        total_images_in_subfolders = 0
        valid_class_folders = 0
        
        for class_folder in class_folders:
            class_images = []
            for ext in self.supported_image_extensions:
                class_images.extend(class_folder.glob(f"*{ext}"))
            
            if len(class_images) >= 3:  # Al menos 3 im√°genes por clase
                valid_class_folders += 1
                total_images_in_subfolders += len(class_images)
        
        # Si la mayor√≠a de im√°genes est√°n en subcarpetas v√°lidas, es clasificaci√≥n
        if len(image_files) > 0:
            ratio = total_images_in_subfolders / len(image_files)
            is_classification = ratio > 0.7 and valid_class_folders >= 2
            
            if is_classification:
                print(f"   ‚úÖ Clasificaci√≥n detectada: {valid_class_folders} clases, {total_images_in_subfolders} im√°genes")
            
            return is_classification
        
        return False
    
    def _is_pascal_voc_format(self, folder_path: Path, image_files: List[Path], xml_files: List[Path]) -> bool:
        """Detecta formato Pascal VOC con validaci√≥n mejorada"""
        if len(xml_files) == 0 or len(image_files) == 0:
            return False
        
        # Verificar correspondencia entre im√°genes y XML
        image_stems = {img.stem for img in image_files}
        xml_stems = {xml.stem for xml in xml_files}
        matching_ratio = len(image_stems & xml_stems) / len(image_stems)
        
        if matching_ratio < 0.3:
            return False
        
        # Verificar estructura XML de Pascal VOC
        voc_annotations = 0
        sample_size = min(10, len(xml_files))
        
        for xml_file in xml_files[:sample_size]:
            try:
                import xml.etree.ElementTree as ET
                tree = ET.parse(xml_file)
                root = tree.getroot()
                
                if (root.tag == 'annotation' and
                    root.find('filename') is not None and
                    root.find('object') is not None and
                    root.find('size') is not None):
                    voc_annotations += 1
            except Exception:
                continue
        
        detection_ratio = voc_annotations / sample_size if sample_size > 0 else 0
        is_voc = detection_ratio >= 0.4
        
        if is_voc:
            print(f"   ‚úÖ Pascal VOC detectado: {voc_annotations}/{sample_size} archivos v√°lidos")
        
        return is_voc
    
    def _analyze_folder_structure(self, folder_path: Path) -> Dict:
        """Analiza la estructura de carpetas"""
        structure = {
            'subdirs': [],
            'common_patterns': [],
            'depth': 0
        }
        
        subdirs = [d.name for d in folder_path.iterdir() if d.is_dir()]
        structure['subdirs'] = subdirs
        
        # Detectar patrones comunes
        common_patterns = {
            'train_val_test': any(name in subdirs for name in ['train', 'val', 'test']),
            'images_labels': any(name in subdirs for name in ['images', 'labels', 'annotations']),
            'class_based': len(subdirs) > 1 and all(len(name) < 20 for name in subdirs)
        }
        
        structure['common_patterns'] = [k for k, v in common_patterns.items() if v]
        
        return structure
    
    def convert_and_organize_dataset(self, folder_path: Path, dataset_type: str, info: Dict) -> bool:
        """üîÑ Convierte y organiza el dataset seg√∫n su tipo."""
        print(f"\nüîÑ PROCESANDO: {folder_path.name} (Tipo: {dataset_type})")
        
        try:
            # Determinar carpeta destino
            if dataset_type == "YOLO":
                target_folder = self.base_path / "_YOLO"
            elif dataset_type == "COCO":
                target_folder = self.base_path / "_COCO"
            elif dataset_type == "UNET":
                target_folder = self.base_path / "_UNET"
            elif dataset_type == "CLASSIFICATION":
                target_folder = self.base_path / "_pure images and masks"
            elif dataset_type == "PASCAL_VOC":
                # Convertir Pascal VOC a YOLO y mover a _YOLO
                return self._convert_pascal_voc_to_yolo(folder_path, info)
            elif dataset_type == "PURE_IMAGES":
                target_folder = self.base_path / "_pure images and masks"
            else:
                print(f"‚ö†Ô∏è Tipo {dataset_type} no soportado para conversi√≥n autom√°tica")
                return False
            
            # Crear carpeta destino si no existe
            target_folder.mkdir(exist_ok=True)
            destination = target_folder / folder_path.name
            
            # Verificar si ya existe
            if destination.exists():
                print(f"‚ö†Ô∏è Ya existe: {destination}")
                response = input("¬øSobrescribir? (s/N): ").strip().lower()
                if response not in ['s', 'si', 's√≠', 'yes', 'y']:
                    return False
                shutil.rmtree(destination)
            
            # Mover la carpeta
            shutil.move(str(folder_path), str(destination))
            print(f"‚úÖ Movido a: {destination}")
            
            self.stats['datasets_movidos'] += 1
            return True
            
        except Exception as e:
            print(f"‚ùå Error procesando {folder_path.name}: {e}")
            self.stats['errores'] += 1
            return False
    
    def _convert_pascal_voc_to_yolo(self, folder_path: Path, info: Dict) -> bool:
        """Convierte Pascal VOC a formato YOLO"""
        print(f"üîÑ Convirtiendo Pascal VOC a YOLO...")
        
        try:
            import xml.etree.ElementTree as ET
            
            # Crear carpeta temporal para la conversi√≥n
            temp_folder = folder_path.parent / f"{folder_path.name}_yolo_converted"
            temp_folder.mkdir(exist_ok=True)
            
            # Buscar archivos XML e im√°genes
            xml_files = list(folder_path.glob("**/*.xml"))
            image_files = []
            for ext in self.supported_image_extensions:
                image_files.extend(folder_path.glob(f"**/*{ext}"))
            
            converted_count = 0
            
            for xml_file in xml_files:
                try:
                    tree = ET.parse(xml_file)
                    root = tree.getroot()
                    
                    # Obtener informaci√≥n de la imagen
                    filename = root.find('filename').text
                    size = root.find('size')
                    width = int(size.find('width').text)
                    height = int(size.find('height').text)
                    
                    # Encontrar imagen correspondiente
                    image_path = None
                    for img in image_files:
                        if img.name == filename or img.stem == Path(filename).stem:
                            image_path = img
                            break
                    
                    if not image_path:
                        continue
                    
                    # Copiar imagen
                    shutil.copy2(image_path, temp_folder / image_path.name)
                    
                    # Convertir anotaciones a YOLO
                    yolo_annotations = []
                    for obj in root.findall('object'):
                        class_name = obj.find('name').text
                        bbox = obj.find('bndbox')
                        
                        xmin = int(bbox.find('xmin').text)
                        ymin = int(bbox.find('ymin').text)
                        xmax = int(bbox.find('xmax').text)
                        ymax = int(bbox.find('ymax').text)
                        
                        # Convertir a formato YOLO
                        x_center = (xmin + xmax) / 2.0 / width
                        y_center = (ymin + ymax) / 2.0 / height
                        bbox_width = (xmax - xmin) / width
                        bbox_height = (ymax - ymin) / height
                        
                        # Usar 0 como class_id por defecto
                        yolo_annotations.append(f"0 {x_center} {y_center} {bbox_width} {bbox_height}")
                    
                    # Guardar archivo YOLO
                    txt_filename = Path(filename).stem + '.txt'
                    with open(temp_folder / txt_filename, 'w') as f:
                        f.write('\n'.join(yolo_annotations))
                    
                    converted_count += 1
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è Error convirtiendo {xml_file.name}: {e}")
                    continue
            
            if converted_count > 0:
                # Mover a _YOLO
                target_folder = self.base_path / "_YOLO"
                target_folder.mkdir(exist_ok=True)
                destination = target_folder / f"{folder_path.name}_converted"
                
                if destination.exists():
                    shutil.rmtree(destination)
                
                shutil.move(str(temp_folder), str(destination))
                
                # Eliminar carpeta original
                shutil.rmtree(folder_path)
                
                print(f"‚úÖ Convertido Pascal VOC ‚Üí YOLO: {converted_count} anotaciones")
                print(f"‚úÖ Guardado en: {destination}")
                
                self.stats['datasets_convertidos'] += 1
                self.stats['datasets_movidos'] += 1
                return True
            else:
                # Limpiar carpeta temporal
                shutil.rmtree(temp_folder)
                return False
                
        except Exception as e:
            print(f"‚ùå Error en conversi√≥n Pascal VOC: {e}")
            return False
    
    def run_auto_organization(self, dry_run: bool = False) -> Dict:
        """üöÄ Ejecuta la organizaci√≥n autom√°tica."""
        print("üöÄ INICIANDO AUTO-ORGANIZACI√ìN DE DATASETS")
        print("="*50)
        
        if dry_run:
            print("üîç MODO DRY-RUN: Solo an√°lisis, sin mover archivos")
        
        # Escanear carpetas no organizadas
        unorganized_folders = self.scan_unorganized_folders()
        
        if not unorganized_folders:
            print("‚úÖ No hay carpetas para organizar")
            return self.stats
        
        print(f"\nüìã PLAN DE ORGANIZACI√ìN:")
        print("-" * 30)
        
        organization_plan = []
        
        for folder in unorganized_folders:
            self.stats['carpetas_analizadas'] += 1
            
            dataset_type, info = self.detect_dataset_type(folder)
            
            if dataset_type not in ["UNKNOWN", "TOO_SMALL"]:
                self.stats['datasets_detectados'] += 1
                
                organization_plan.append({
                    'folder': folder,
                    'type': dataset_type,
                    'info': info
                })
                
                print(f"üìÅ {folder.relative_to(self.base_path)}")
                print(f"   üîç Tipo detectado: {dataset_type}")
                print(f"   üìä Im√°genes: {info['images']} | Tama√±o: {info['size_mb']:.1f} MB")
                
                if dataset_type == "YOLO":
                    print(f"   üìÅ Destino: _YOLO/")
                elif dataset_type == "COCO":
                    print(f"   üìÅ Destino: _COCO/")
                elif dataset_type == "UNET":
                    print(f"   üìÅ Destino: _UNET/")
                elif dataset_type == "CLASSIFICATION":
                    print(f"   üìÅ Destino: _pure images and masks/")
                elif dataset_type == "PASCAL_VOC":
                    print(f"   üîÑ Convertir a YOLO ‚Üí _YOLO/")
                elif dataset_type == "PURE_IMAGES":
                    print(f"   üìÅ Destino: _pure images and masks/")
                print()
            elif dataset_type == "TOO_SMALL":
                print(f"üìÅ {folder.relative_to(self.base_path)}")
                print(f"   ‚ö†Ô∏è Muy peque√±o: {info['images']} im√°genes < {self.min_images}")
                print()
            else:
                print(f"üìÅ {folder.relative_to(self.base_path)}")
                print(f"   ‚ùì Tipo no reconocido")
                print(f"   üìä Im√°genes: {info['images']}, Otros: {info['total_files'] - info['images']}")
                print()
        
        if not organization_plan:
            print("‚ö†Ô∏è No se detectaron datasets v√°lidos para organizar")
            return self.stats
        
        # Confirmar ejecuci√≥n
        if not dry_run:
            print(f"\nüéØ RESUMEN:")
            print(f"   üìÅ Carpetas a procesar: {len(organization_plan)}")
            print(f"   üîÑ Conversiones necesarias: {sum(1 for p in organization_plan if p['type'] == 'PASCAL_VOC')}")
            
            response = input(f"\n¬øProceder con la organizaci√≥n? (s/N): ").strip().lower()
            if response not in ['s', 'si', 's√≠', 'yes', 'y']:
                print("‚ùå Operaci√≥n cancelada")
                return self.stats
        
        # Ejecutar organizaci√≥n
        if not dry_run:
            print(f"\nüîÑ EJECUTANDO ORGANIZACI√ìN...")
            print("-" * 30)
            
            for plan in organization_plan:
                success = self.convert_and_organize_dataset(
                    plan['folder'], 
                    plan['type'], 
                    plan['info']
                )
                
                if success:
                    print(f"‚úÖ {plan['folder'].name} organizado correctamente")
                else:
                    print(f"‚ùå Error organizando {plan['folder'].name}")
        
        return self.stats
    
    def print_final_stats(self):
        """üìä Imprime estad√≠sticas finales."""
        print(f"\nüìä ESTAD√çSTICAS FINALES:")
        print("="*40)
        print(f"üìÅ Carpetas analizadas: {self.stats['carpetas_analizadas']}")
        print(f"ÔøΩ Subcarpetas encontradas: {self.stats['subcarpetas_encontradas']}")
        print(f"ÔøΩüîç Datasets detectados: {self.stats['datasets_detectados']}")
        print(f"ÔøΩ Datasets muy peque√±os: {self.stats['datasets_muy_peque√±os']}")
        print(f"ÔøΩüîÑ Datasets convertidos: {self.stats['datasets_convertidos']}")
        print(f"üì¶ Datasets movidos: {self.stats['datasets_movidos']}")
        print(f"‚ùå Errores: {self.stats['errores']}")
        
        if self.stats['datasets_detectados'] > 0:
            success_rate = (self.stats['datasets_movidos'] / self.stats['datasets_detectados']) * 100
            print(f"‚úÖ Tasa de √©xito: {success_rate:.1f}%")
        
        print(f"\nüí° Par√°metros utilizados:")
        print(f"   üñºÔ∏è M√≠nimo de im√°genes por dataset: {self.min_images}")
        print(f"   üìÅ Carpetas organizadas excluidas: {', '.join(self.organized_folders)}")


def main():
    """üöÄ Funci√≥n principal"""
    print("ü§ñ AUTO-ORGANIZADOR INTELIGENTE DE DATASETS DENTALES")
    print("="*60)
    print()
    print("Esta herramienta:")
    print("‚Ä¢ üîç Escanea recursivamente carpetas en _dataSets")
    print("‚Ä¢ ü§ñ Detecta autom√°ticamente el tipo de dataset")
    print("‚Ä¢ üîÑ Convierte formatos cuando es necesario")
    print("‚Ä¢ üì¶ Mueve a la carpeta correspondiente")
    print("‚Ä¢ üìä Proporciona estad√≠sticas detalladas")
    print()
    
    # Configuraci√≥n
    min_images = 5
    config_response = input(f"¬øCambiar m√≠nimo de im√°genes por dataset? (actual: {min_images}): ").strip()
    if config_response and config_response.isdigit():
        min_images = int(config_response)
        print(f"‚úÖ Usando m√≠nimo: {min_images} im√°genes")
    
    organizer = SmartDatasetOrganizer(min_images=min_images)
    
    # Preguntar si hacer dry-run primero
    dry_run_response = input("\n¬øHacer an√°lisis previo sin mover archivos? (S/n): ").strip().lower()
    dry_run = dry_run_response not in ['n', 'no', 'nope']
    
    # Ejecutar organizaci√≥n
    stats = organizer.run_auto_organization(dry_run=dry_run)
    
    # Mostrar estad√≠sticas
    organizer.print_final_stats()
    
    # Si fue dry-run, preguntar si ejecutar realmente
    if dry_run and stats['datasets_detectados'] > 0:
        print(f"\nüí° El an√°lisis encontr√≥ {stats['datasets_detectados']} datasets organizables.")
        execute_response = input("¬øEjecutar la organizaci√≥n real? (s/N): ").strip().lower()
        
        if execute_response in ['s', 'si', 's√≠', 'yes', 'y']:
            print(f"\nüîÑ EJECUTANDO ORGANIZACI√ìN REAL...")
            organizer.stats = {k: 0 for k in organizer.stats.keys()}  # Reset stats
            organizer.run_auto_organization(dry_run=False)
            organizer.print_final_stats()


if __name__ == "__main__":
    main()
